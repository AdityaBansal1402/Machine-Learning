{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aeabcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.5 MB 1.3 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.1/1.5 MB 1.3 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 0.3/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 0.7/1.5 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.4/1.5 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 6.4 MB/s eta 0:00:00\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 0.0/96.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 96.6/96.6 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib in c:\\users\\aditya bansal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2023.3.23-cp311-cp311-win_amd64.whl (267 kB)\n",
      "     ---------------------------------------- 0.0/267.9 kB ? eta -:--:--\n",
      "     -------------------------------------  266.2/267.9 kB 8.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 267.9/267.9 kB 5.5 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 0.0/77.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 77.1/77.1 kB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\aditya bansal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.3 nltk-3.8.1 regex-2023.3.23 tqdm-4.65.0\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0907c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd9c73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8467e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11fe8d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e9acd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=brown.sents(categories='fiction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c435686c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'`` I think by the end of next week he could get out in the air a little .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(data[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f438126d",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa7bf2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "document=\"\"\"It was a very pleasant day. The weather was cool and there were light showers. I went to the market to buy some fruits.\"\"\"\n",
    "sentence=\"Send all the 50 documents related to chapter 1,2,3 at aditya@hehe.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57f161c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8a1e38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It was a very pleasant day.', 'The weather was cool and there were light showers.', 'I went to the market to buy some fruits.']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "sents=sent_tokenize(document)\n",
    "print(sents)\n",
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "124411a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Send',\n",
       " 'all',\n",
       " 'the',\n",
       " '50',\n",
       " 'documents',\n",
       " 'related',\n",
       " 'to',\n",
       " 'chapter',\n",
       " '1,2,3',\n",
       " 'at',\n",
       " 'aditya@hehe.com']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38194fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6151a63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Send', 'all', 'the', '50', 'documents', 'related', 'to', 'chapter', '1,2,3', 'at', 'aditya', '@', 'hehe.com']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da032a7",
   "metadata": {},
   "source": [
    "## stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b3038cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67c25abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw=set(stopwords.words('english'))\n",
    "#common words we can skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4df29857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'out', 'did', 'of', 'me', \"needn't\", \"mightn't\", 'them', 'doesn', 'than', \"wasn't\", 'there', 'from', 'then', 'needn', 'is', 'do', 'their', 'between', 'you', 'here', 'an', 'below', \"you're\", 'such', 'herself', 'my', 'at', 'shan', 'not', 'are', 'very', 'which', 'in', \"didn't\", 'again', 'couldn', 'this', 'with', 'won', 'as', 'until', 'these', 'have', 'be', 'yourself', \"weren't\", 'off', 'both', \"hadn't\", \"hasn't\", 'your', 'having', 'just', 'down', 'some', 'can', \"it's\", 'yourselves', 'only', 'against', 'to', 'were', 'mustn', 'it', \"you'd\", 'for', \"doesn't\", 're', 'own', \"she's\", 'further', \"shouldn't\", 'over', 'doing', 'too', 'should', \"you've\", 'wasn', 'while', 'ma', \"isn't\", 'was', 'its', 'and', 'through', 'if', \"shan't\", 'because', 'aren', 'ours', 'up', 'but', 'ain', 'itself', 'isn', 'the', 'where', 'themselves', \"you'll\", 'theirs', 'what', 'shouldn', \"don't\", 'haven', 'whom', 'ourselves', 'they', \"that'll\", 'most', \"should've\", 'under', 'will', 'yours', 'other', 'll', 'd', 'o', \"aren't\", 'about', 'm', 'him', \"won't\", 'so', 'or', \"couldn't\", 'don', 've', 'how', 't', 'our', 'few', 'does', 'on', 'by', 'i', 'himself', 'weren', 'wouldn', 'myself', 'during', 'why', 'being', 'no', 'didn', \"haven't\", 'she', 'that', 'y', 'hers', \"mustn't\", 'same', 'above', 'am', 'mightn', 'when', 'who', 'those', 'into', 'all', 'has', 'nor', 'now', 'after', 'any', 'each', 'her', 'before', 'hadn', 'hasn', 'once', 's', 'he', \"wouldn't\", 'been', 'his', 'had', 'we', 'a', 'more'}\n"
     ]
    }
   ],
   "source": [
    "print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b385edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text,stopwords):\n",
    "    useful_words=[w for w in text if w not in stopwords or w in 'not']\n",
    "    return useful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a8b4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"I am not bothered by her very much now.\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e603a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_text=remove_stopwords(text,sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54430f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'not', 'bothered', 'much', 'now.']\n"
     ]
    }
   ],
   "source": [
    "print(useful_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b433d074",
   "metadata": {},
   "source": [
    "## tokenization using regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ea9c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "##regexpal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d43f0e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Send',\n",
       " 'all',\n",
       " 'the',\n",
       " '50',\n",
       " 'documents',\n",
       " 'related',\n",
       " 'to',\n",
       " 'chapter',\n",
       " '1,2,3',\n",
       " 'at',\n",
       " 'aditya@hehe.com']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b561ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87dcd80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=RegexpTokenizer('[a-zA-Z@.]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5f611abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "use=tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e810eca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Send',\n",
       " 'all',\n",
       " 'the',\n",
       " 'documents',\n",
       " 'related',\n",
       " 'to',\n",
       " 'chapter',\n",
       " 'at',\n",
       " 'aditya@hehe.com']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c1c03",
   "metadata": {},
   "source": [
    "## stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2c079534",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"Fozes love to make jumps. The quick brown fox was seen jumping over the lovely dog from high wall\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "37171596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# snowball stemmer , porter , lancaster stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d34c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer,PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac81ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3b409923",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "33be52e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jump'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('jumping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7320aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#snowball is multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "708fad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f93d3c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jump'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.stem(\"jumping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8b63d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "35a38c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "447bca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "31e726dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jumping'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemmatize('jumping')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb662b6",
   "metadata": {},
   "source": [
    "## vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e51da1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=['India cricket team will win World Cup,says capt. Rohit Sharma. World cup will be held at Sri Lanka',\n",
    "       'We will win next Lok Sabha Elections says confident Indian PM',\n",
    "       'The nobel laurate won the hearts of the people.',\n",
    "       'The movie Raazi is an exciting Indian spy thriller based upon a real story.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d5d8d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0c19373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "48d28af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cb13a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize=vectorize.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "68bfca66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1 0 1 2 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0\n",
      "  0 0 2 1 0 2]\n",
      " [0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0\n",
      "  0 1 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 3 0\n",
      "  0 0 0 0 1 0]\n",
      " [1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 1\n",
      "  1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "451d877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'india': 12, 'cricket': 6, 'team': 33, 'will': 38, 'win': 39, 'world': 41, 'cup': 7, 'says': 28, 'capt': 4, 'rohit': 26, 'sharma': 29, 'be': 3, 'held': 11, 'at': 1, 'sri': 31, 'lanka': 15, 'we': 37, 'next': 19, 'lok': 17, 'sabha': 27, 'elections': 8, 'confident': 5, 'indian': 13, 'pm': 23, 'the': 34, 'nobel': 20, 'laurate': 16, 'won': 40, 'hearts': 10, 'of': 21, 'people': 22, 'movie': 18, 'raazi': 24, 'is': 14, 'an': 0, 'exciting': 9, 'spy': 30, 'thriller': 35, 'based': 2, 'upon': 36, 'real': 25, 'story': 32}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d85f4855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### reverse mapping\n",
    "numbers=vectorize[2]\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7fb98bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['at', 'be', 'capt', 'cricket', 'cup', 'held', 'india', 'lanka',\n",
       "        'rohit', 'says', 'sharma', 'sri', 'team', 'will', 'win', 'world'],\n",
       "       dtype='<U9'),\n",
       " array(['confident', 'elections', 'indian', 'lok', 'next', 'pm', 'sabha',\n",
       "        'says', 'we', 'will', 'win'], dtype='<U9'),\n",
       " array(['hearts', 'laurate', 'nobel', 'of', 'people', 'the', 'won'],\n",
       "       dtype='<U9'),\n",
       " array(['an', 'based', 'exciting', 'indian', 'is', 'movie', 'raazi',\n",
       "        'real', 'spy', 'story', 'the', 'thriller', 'upon'], dtype='<U9')]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.inverse_transform(vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cd7330c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#biigram- to club words together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c92ddbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_1=[\"this is good movie\"]\n",
    "sent_2=[\"this is good movie but actor is not present\"]\n",
    "sent_3=[\"this is not good movie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0d2de581",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e47c98eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 1],\n",
       "       [1, 0, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=[sen_1[0],sent_3[0]]\n",
    "cv.fit_transform(docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "96eebbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this is': 4, 'is good': 1, 'good movie': 0, 'is not': 2, 'not good': 3}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070cc3df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
